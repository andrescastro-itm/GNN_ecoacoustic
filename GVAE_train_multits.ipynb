{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8b10ff2890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv\n",
    "\n",
    "from GraphDataset import MyDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "torch.manual_seed(611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   1         2         3\n",
      "field_numb                              \n",
      "RZUA01      1.000000  0.000000  0.000000\n",
      "RZUA02      1.000000  0.000000  0.000000\n",
      "RZUA04      0.589278  0.410722  0.000000\n",
      "RZUA05      0.892664  0.000000  0.107336\n",
      "RZUA06      0.938423  0.000000  0.061577\n"
     ]
    }
   ],
   "source": [
    "# Load soft labels with membership level to each cover\n",
    "\n",
    "df_data = pd.read_csv('data/ReyZamuro_softLabels.csv',index_col=0)\n",
    "df_data = df_data.drop('RZUB02')\n",
    "df_data = df_data.drop('RZUA03b')\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of ARUs and labels\n",
    "\n",
    "DatosN = list(df_data.index)\n",
    "Clases = df_data.values#.argmax(1)\n",
    "etiquetasN = torch.tensor(Clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "features = 'YAMNet'#'PANNs'#'YAMNet' #'VGGish'#'AI'\n",
    "\n",
    "train_dataset = MyDataset(ListaArchivos=DatosN,\n",
    "                          etiquetas=etiquetasN, caract=features)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZUA01\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUA10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB01\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUB11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC01\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUC12\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD01M\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD12\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUD13\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE01\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE12\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUE13\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF12\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUF13\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG12\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUG13\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH02\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH03\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH04\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH05\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH06\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH07\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH08\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH09\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH10\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH11\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH12\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n",
      "RZUH13\n",
      "Data1.shape=torch.Size([3, 24, 1024])\n"
     ]
    }
   ],
   "source": [
    "unpacked_data = [train_dataset[i][0] for i in range(len(train_dataset))]\n",
    "x = torch.stack(unpacked_data, dim=0).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize_along_dim(tensor, dim):\n",
    "    # Get min and max values along the specified dimension, keeping dimensions\n",
    "    min_vals, _ = torch.min(tensor, dim=dim, keepdim=True)\n",
    "    max_vals, _ = torch.max(tensor, dim=dim, keepdim=True)\n",
    "    \n",
    "    # Handle the case where min and max are the same (to avoid division by zero)\n",
    "    diff = max_vals - min_vals\n",
    "    diff[diff == 0] = 1.0  # Replace zeros with ones to avoid division by zero\n",
    "    \n",
    "    # Normalize the tensor\n",
    "    normalized = (tensor - min_vals) / diff\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 92, 24, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = min_max_normalize_along_dim(x, dim=2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import edge_creation_nodeinfo, is_connected, edge_creation_geoDistance, plot_distance_matrix_heatmap, edge_creation_coverinfo\n",
    "from torch_geometric.utils import is_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the graph Data(x=[92, 24, 1024], edge_index=[2, 606]) connected? True\n",
      "Is the graph undirected True\n",
      "Is the graph Data(x=[92, 24, 1024], edge_index=[2, 606]) connected? True\n",
      "Is the graph undirected True\n",
      "Is the graph Data(x=[92, 24, 1024], edge_index=[2, 606]) connected? True\n",
      "Is the graph undirected True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs = edge_creation_coverinfo(torch.tensor(df_data.values), x,'knn', k_neigh=5)\n",
    "for i in graphs:\n",
    "    print(f\"Is the graph {i} connected? {is_connected(i)}\")\n",
    "    print(f'Is the graph undirected {is_undirected(i.edge_index)}')\n",
    "\n",
    "max_nodes = max([data.num_nodes for data in graphs])\n",
    "num_feat = graphs[0].x.shape[-1]\n",
    "num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(graphs, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del graphs, x, unpacked_data, train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear modelo y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MatrixGCNVAE_MT, MatrixGATVAE_MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if features =='PANNs' or features == \"YAMNet\":\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetasN = etiquetasN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 1.9383\n",
      "====> Adj loss: 0.9284, Recon: 0.0328, KL: 0.1344, Class: 0.8427, Accuracy: 65.33%\n",
      "Epoch: 040, Loss: 1.8926\n",
      "====> Adj loss: 0.9284, Recon: 0.0315, KL: 0.1808, Class: 0.7518, Accuracy: 71.67%\n",
      "Epoch: 060, Loss: 1.9119\n",
      "====> Adj loss: 0.9284, Recon: 0.0316, KL: 0.1678, Class: 0.7841, Accuracy: 69.67%\n",
      "Epoch: 080, Loss: 1.8754\n",
      "====> Adj loss: 0.9284, Recon: 0.0313, KL: 0.2049, Class: 0.7108, Accuracy: 75.00%\n",
      "Epoch: 100, Loss: 1.8698\n",
      "====> Adj loss: 0.9284, Recon: 0.0314, KL: 0.1799, Class: 0.7302, Accuracy: 73.33%\n",
      "Epoch: 120, Loss: 1.8942\n",
      "====> Adj loss: 0.9284, Recon: 0.0314, KL: 0.1766, Class: 0.7579, Accuracy: 73.33%\n",
      "Epoch: 140, Loss: 1.8899\n",
      "====> Adj loss: 0.9284, Recon: 0.0314, KL: 0.1654, Class: 0.7647, Accuracy: 75.00%\n",
      "Epoch: 160, Loss: 1.8311\n",
      "====> Adj loss: 0.9284, Recon: 0.0313, KL: 0.1489, Class: 0.7224, Accuracy: 78.67%\n",
      "Epoch: 180, Loss: 1.8305\n",
      "====> Adj loss: 0.9284, Recon: 0.0312, KL: 0.1686, Class: 0.7023, Accuracy: 79.67%\n",
      "Epoch: 200, Loss: 1.8021\n",
      "====> Adj loss: 0.9284, Recon: 0.0311, KL: 0.1395, Class: 0.7031, Accuracy: 78.33%\n",
      "Epoch: 220, Loss: 1.7850\n",
      "====> Adj loss: 0.9284, Recon: 0.0312, KL: 0.1317, Class: 0.6937, Accuracy: 79.67%\n",
      "Epoch: 240, Loss: 1.7482\n",
      "====> Adj loss: 0.9284, Recon: 0.0309, KL: 0.1329, Class: 0.6560, Accuracy: 82.00%\n",
      "Epoch: 260, Loss: 1.7395\n",
      "====> Adj loss: 0.9284, Recon: 0.0310, KL: 0.1139, Class: 0.6662, Accuracy: 80.67%\n",
      "Epoch: 280, Loss: 1.7323\n",
      "====> Adj loss: 0.9284, Recon: 0.0309, KL: 0.1291, Class: 0.6438, Accuracy: 81.67%\n",
      "Epoch: 300, Loss: 1.7339\n",
      "====> Adj loss: 0.9284, Recon: 0.0310, KL: 0.1246, Class: 0.6499, Accuracy: 82.33%\n",
      "Epoch: 320, Loss: 1.7247\n",
      "====> Adj loss: 0.9284, Recon: 0.0310, KL: 0.1282, Class: 0.6371, Accuracy: 82.33%\n",
      "Epoch: 340, Loss: 1.7178\n",
      "====> Adj loss: 0.9284, Recon: 0.0309, KL: 0.1226, Class: 0.6359, Accuracy: 81.67%\n",
      "Epoch: 360, Loss: 1.7025\n",
      "====> Adj loss: 0.9284, Recon: 0.0309, KL: 0.1276, Class: 0.6156, Accuracy: 84.00%\n",
      "Epoch: 380, Loss: 1.6914\n",
      "====> Adj loss: 0.9284, Recon: 0.0308, KL: 0.1236, Class: 0.6086, Accuracy: 81.67%\n",
      "Epoch: 400, Loss: 1.6975\n",
      "====> Adj loss: 0.9284, Recon: 0.0309, KL: 0.1331, Class: 0.6051, Accuracy: 82.33%\n",
      "Epoch: 420, Loss: 1.6835\n",
      "====> Adj loss: 0.9284, Recon: 0.0309, KL: 0.1200, Class: 0.6041, Accuracy: 85.67%\n",
      "Epoch: 440, Loss: 1.6752\n",
      "====> Adj loss: 0.9284, Recon: 0.0308, KL: 0.1330, Class: 0.5830, Accuracy: 84.67%\n",
      "Epoch: 460, Loss: 1.6716\n",
      "====> Adj loss: 0.9284, Recon: 0.0308, KL: 0.1210, Class: 0.5914, Accuracy: 83.67%\n",
      "Epoch: 480, Loss: 1.6712\n",
      "====> Adj loss: 0.9284, Recon: 0.0308, KL: 0.1236, Class: 0.5884, Accuracy: 82.33%\n",
      "Epoch: 500, Loss: 1.6662\n",
      "====> Adj loss: 0.9284, Recon: 0.0307, KL: 0.1272, Class: 0.5800, Accuracy: 82.00%\n",
      "Epoch: 520, Loss: 1.6698\n",
      "====> Adj loss: 0.9284, Recon: 0.0306, KL: 0.1245, Class: 0.5862, Accuracy: 84.00%\n",
      "Epoch: 540, Loss: 1.6499\n",
      "====> Adj loss: 0.9284, Recon: 0.0307, KL: 0.1128, Class: 0.5781, Accuracy: 86.67%\n",
      "Epoch: 560, Loss: 1.6478\n",
      "====> Adj loss: 0.9284, Recon: 0.0306, KL: 0.1220, Class: 0.5669, Accuracy: 86.33%\n",
      "Epoch: 580, Loss: 1.6458\n",
      "====> Adj loss: 0.9284, Recon: 0.0306, KL: 0.1145, Class: 0.5723, Accuracy: 84.67%\n",
      "Early stopping activado en la época 581\n",
      "Métricas guardadas en modelsGVAE_semi/training_metrics_YAMNet_GCN_model.csv\n"
     ]
    }
   ],
   "source": [
    "model = MatrixGCNVAE_MT(in_channels=64*num_feat, hidden_channels=4*num_feat, latent_dim=int(num_feat/8), num_nodes=max_nodes, num_classes=3)\n",
    "model = model.to(device)\n",
    "etiquetasN = etiquetasN.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.01 GCN\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    model.double()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_feature_loss = 0\n",
    "    total_adj_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    total_class_loss = 0\n",
    "    total_accuracy = 0\n",
    "    graph_count = 0\n",
    "\n",
    "\n",
    "    for graph in train_loader:\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        node_reconstruction, adj_reconstruction, mu, logvar, class_logits = model(graph.x.double(), graph.edge_index)\n",
    "        loss, feature_loss, adj_loss, kl_loss, class_loss = model.loss_function(node_reconstruction, adj_reconstruction, class_logits, etiquetasN, graph.x.double(),\n",
    "                                                                    graph.edge_index, mu, logvar, alpha=1.0, beta=0.1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy = F.softmax(class_logits, dim=1).argmax(dim=1).eq(etiquetasN.argmax(dim=1)).sum()\n",
    "\n",
    "        # Acumular métricas si deseas promediarlas después\n",
    "        total_loss += loss.item()\n",
    "        total_feature_loss += feature_loss.item()\n",
    "        total_adj_loss += adj_loss.item()\n",
    "        total_kl_loss += kl_loss.item()\n",
    "        total_class_loss += class_loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        graph_count += 1\n",
    "        # print(f'{F.softmax(class_logits, dim=1).argmax(dim=1)=}, {etiquetasN.argmax(dim=1)=}')\n",
    "    avg_loss = total_loss / graph_count\n",
    "    avg_feature_loss = total_feature_loss / graph_count\n",
    "    avg_adj_loss = total_adj_loss / graph_count\n",
    "    avg_kl_loss = total_kl_loss / graph_count\n",
    "    avg_class_loss = total_class_loss / graph_count\n",
    "    avg_accuracy = total_accuracy / graph_count\n",
    "    \n",
    "    return avg_loss, avg_feature_loss, avg_adj_loss, avg_kl_loss, avg_class_loss, avg_accuracy\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Configuración para early stopping\n",
    "patience = 40  # Número de épocas a esperar para una mejora\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "early_stop = False\n",
    "\n",
    "# Para guardar todas las métricas\n",
    "all_metrics = []\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    loss, feature_loss, adj_loss, kl_loss, class_loss, accuracy = train()\n",
    "\n",
    "    # Guardar métricas de la época actual\n",
    "    metrics = {\n",
    "        'epoch': epoch,\n",
    "        'loss': loss,\n",
    "        'feature_loss': feature_loss,\n",
    "        'adj_loss': adj_loss,\n",
    "        'kl_loss': kl_loss,\n",
    "        'class_loss': class_loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        print(f'====> Adj loss: {adj_loss:.4f}, '\n",
    "          f'Recon: {feature_loss:.4f}, KL: {kl_loss:.4f}, Class: {class_loss:.4f}, '\n",
    "          f'Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "    # Early stopping y guardado del mejor modelo\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f'modelsGVAE_semi/{features}_GCN_model_weights.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping activado en la época {epoch}\")\n",
    "            early_stop = True\n",
    "    \n",
    "    # Si se activa early stopping, salir del bucle\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "# Guardar todas las métricas en un CSV\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "csv_path = f'modelsGVAE_semi/training_metrics_{features}_GCN_model.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"Métricas guardadas en {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixGATVAE_MT(in_channels=64*num_feat, hidden_channels=4*num_feat, latent_dim=int(num_feat/8), num_nodes=max_nodes, num_classes=3)\n",
    "model = model.to(device)\n",
    "etiquetasN = etiquetasN.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #0.01 GCN\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    model.double()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_feature_loss = 0\n",
    "    total_adj_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    total_class_loss = 0\n",
    "    total_accuracy = 0\n",
    "    graph_count = 0\n",
    "\n",
    "\n",
    "    for graph in train_loader:\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        node_reconstruction, adj_reconstruction, mu, logvar, class_logits = model(graph.x.double(), graph.edge_index)\n",
    "        loss, feature_loss, adj_loss, kl_loss, class_loss = model.loss_function(node_reconstruction, adj_reconstruction, class_logits, etiquetasN, graph.x.double(),\n",
    "                                                                    graph.edge_index, mu, logvar, alpha=1.0, beta=0.1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy = F.softmax(class_logits, dim=1).argmax(dim=1).eq(etiquetasN.argmax(dim=1)).sum()\n",
    "\n",
    "        # Acumular métricas si deseas promediarlas después\n",
    "        total_loss += loss.item()\n",
    "        total_feature_loss += feature_loss.item()\n",
    "        total_adj_loss += adj_loss.item()\n",
    "        total_kl_loss += kl_loss.item()\n",
    "        total_class_loss += class_loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        graph_count += 1\n",
    "        # print(f'{F.softmax(class_logits, dim=1).argmax(dim=1)=}, {etiquetasN.argmax(dim=1)=}')\n",
    "    avg_loss = total_loss / graph_count\n",
    "    avg_feature_loss = total_feature_loss / graph_count\n",
    "    avg_adj_loss = total_adj_loss / graph_count\n",
    "    avg_kl_loss = total_kl_loss / graph_count\n",
    "    avg_class_loss = total_class_loss / graph_count\n",
    "    avg_accuracy = total_accuracy / graph_count\n",
    "    \n",
    "    return avg_loss, avg_feature_loss, avg_adj_loss, avg_kl_loss, avg_class_loss, avg_accuracy\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Configuración para early stopping\n",
    "patience = 40  # Número de épocas a esperar para una mejora\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "early_stop = False\n",
    "\n",
    "# Para guardar todas las métricas\n",
    "all_metrics = []\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    loss, feature_loss, adj_loss, kl_loss, class_loss, accuracy = train()\n",
    "\n",
    "    # Guardar métricas de la época actual\n",
    "    metrics = {\n",
    "        'epoch': epoch,\n",
    "        'loss': loss,\n",
    "        'feature_loss': feature_loss,\n",
    "        'adj_loss': adj_loss,\n",
    "        'kl_loss': kl_loss,\n",
    "        'class_loss': class_loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        print(f'====> Adj loss: {adj_loss:.4f}, '\n",
    "          f'Recon: {feature_loss:.4f}, KL: {kl_loss:.4f}, Class: {class_loss:.4f}, '\n",
    "          f'Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "    # Early stopping y guardado del mejor modelo\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f'modelsGVAE_semi/{features}_GAT_model_weights.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping activado en la época {epoch}\")\n",
    "            early_stop = True\n",
    "    \n",
    "    # Si se activa early stopping, salir del bucle\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "# Guardar todas las métricas en un CSV\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "csv_path = f'modelsGVAE_semi/training_metrics_{features}_GAT_model.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"Métricas guardadas en {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchGeometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
